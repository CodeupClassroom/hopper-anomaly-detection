{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "561910cd",
   "metadata": {},
   "source": [
    "# Time Series Anomaly Detection\n",
    "\n",
    "We will use a concept known as **Bollinger Bands** to discover when behavior changes from what is \"expected\" or normal. **Bollinger Bands** is a volatility indicator and commonly used in stock market trading.\n",
    "\n",
    "<u>Scenario</u>: Discover anomalies in number of web pages accessed in a day by a user. Is there a bot copying the curriculum?\n",
    "\n",
    "We will accomplish this by breaking down to the following tasks:\n",
    "\n",
    "1. Acquire the data\n",
    "1. Prepare the data\n",
    "1. Make the analysis process (which we will discuss later) work over all users.\n",
    "1. Turn the analysis process and calculations into a function that can be used to loop through for each user.\n",
    "1. Test the function on a single user.\n",
    "1. Analyze by looping over all users.\n",
    "\n",
    "The analysis process will look like this, for each user:\n",
    "\n",
    "1. Compute necessary metrics to arrive at the final metric, %b (percent-b).\n",
    "1. Add user id to the dataframe that contains all the metrics, including %b.\n",
    "1. Filter to rows where %b indicates anomaly (i.e. > 1)\n",
    "1. Append rows of anomalies of new user to previous users' anomalous activity.\n",
    "\n",
    "Finally, we will do a quick sample of exploration of the anomalies. There is much more you can do!\n",
    "\n",
    "Your exercise will be to add comments, markdown, and docstrings to the code in this lesson."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e135ecdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import env"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "104d2ccc",
   "metadata": {},
   "source": [
    "## Acquire\n",
    "\n",
    "After doing some research, some experimentation of performing actions and watching the logs, we discovered what each of the fields represent. We then parse and name the fields accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e99758e",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = f'mysql+pymysql://{env.user}:{env.password}@{env.host}/curriculum_logs'\n",
    "query = '''\n",
    "SELECT date,\n",
    "       path as endpoint,\n",
    "       user_id,\n",
    "       cohort_id,\n",
    "       ip as source_ip\n",
    "FROM logs;\n",
    "'''\n",
    "df = pd.read_sql(query, url)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81c2829b",
   "metadata": {},
   "source": [
    "## Prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0cb7ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.date = pd.to_datetime(df.date)\n",
    "df = df.set_index(df.date)\n",
    "pages = df['endpoint'].resample('d').count()\n",
    "pages.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f745b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "pages.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "711a4c1f",
   "metadata": {},
   "source": [
    "No need to split because we are not modeling, we are using statistics to identify low probability cases.\n",
    "\n",
    "### Exponential Moving Average\n",
    "Simple Moving Average (SMA) time series are much less noisy than the time series of the original data points. The challenge with SMA, however, is that the values of SMA lag the original values. This means that changes in the trend are only seen with a delay (lag) of L time units. For datasets that contain rapid trend shifts, a SMA may simply be too slow to be useful. \n",
    "\n",
    "Exponential Moving Average (EMA) helps reduce the lag induced by the use of the SMA. It does this by putting more weight on more recent observations, while the SMA weights all observations equally.\n",
    "\n",
    "The EMA function looks like this:\n",
    "\n",
    "### EMA<sub>*t*</sub> = α ∗ (*t*<sub>0</sub> − EMA<sub>*t−1*</sub>) + EMA<sub>*t−1*</sub>\n",
    "\n",
    "Where:\n",
    "\n",
    "- t<sub>0</sub> = Latest value\n",
    "- t<sub>−1</sub> = Previous value\n",
    "- EMA<sub>*t−1*</sub> = Exponential moving average of previous day.\n",
    "- The multiplier: α = 2/(M+1)\n",
    "\n",
    "and \n",
    "\n",
    "- M = Number of time periods, span of the window\n",
    "\n",
    "However, we will use the pandas `ewm()` (Exponential Weighted functions) to compute our EMA. So we just need to define the following:\n",
    "\n",
    "M = `span` argument = number of time periods. We will try 7 days, 14 days, and 30 days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe6e937",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7 day EMA\n",
    "ema_7d = pages.ewm(span=7).mean()\n",
    "ema_7d.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b89cf41",
   "metadata": {},
   "source": [
    "Notice how there are no missing values. `ewm()` will use as many values as are available to compute the mean. \n",
    "\n",
    "So if the span is 7 days, but there is only one day of data available (i.e. the first day), the EMA will equal the first value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7bf8044",
   "metadata": {},
   "outputs": [],
   "source": [
    "ema_7d[0] == pages[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce683c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pages.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c4de05f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 14 days EMA\n",
    "ema_14d = pages.ewm(span=14).mean()\n",
    "ema_14d.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ea94f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 30 days EMA\n",
    "ema_30d = pages.ewm(span=30).mean()\n",
    "ema_30d.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad9399b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 90 days EMA\n",
    "ema_90d = pages.ewm(span=90).mean()\n",
    "ema_90d.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32b9aeae",
   "metadata": {},
   "source": [
    "> Remember! These are *exponential* moving averages, not simple!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc6abf43",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(16,8))\n",
    "\n",
    "ax.plot(pages.index, pages, label='Daily', alpha=.5)\n",
    "\n",
    "ax.plot(pages.index, ema_7d, label = '7-day EMA')\n",
    "ax.plot(pages.index, ema_14d, label = '14-day EMA')\n",
    "ax.plot(pages.index, ema_30d, label = '30-day EMA')\n",
    "ax.plot(pages.index, ema_90d, label = '90-day EMA')\n",
    "\n",
    "ax.legend(loc='best')\n",
    "ax.set_ylabel('Number of pages')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f377dae9",
   "metadata": {},
   "source": [
    "Let's look at a smaller date range to see how these EMAs react to changes in value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3376e82c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(16,8))\n",
    "\n",
    "ax.plot(pages.index[:100], pages[:100], label='Daily', alpha=.5)\n",
    "ax.plot(pages.index[:100], ema_7d[:100], label = '7-day EMA')\n",
    "ax.plot(pages.index[:100], ema_14d[:100], label = '14-day EMA')\n",
    "ax.plot(pages.index[:100], ema_30d[:100], label = '30-day EMA')\n",
    "ax.plot(pages.index[:100], ema_90d[:100], label = '90-day EMA')\n",
    "\n",
    "ax.legend(loc='best')\n",
    "ax.set_ylabel('Number of pages')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8764c10a",
   "metadata": {},
   "source": [
    "## Bollinger Bands\n",
    "\n",
    "- A volatility indicator commonly used in stock market, forex, and cryptocurrency trading.\n",
    "- Made up of 3 lines, the Upper Band (UB), the Lower Band (LB) and the Midband.\n",
    "- Based on the exponential moving average\n",
    "\n",
    "### Midband\n",
    "\n",
    "The Exponential Moving Average\n",
    "\n",
    "`midband = train.ewm(span=30).mean()`\n",
    "\n",
    "### Upper & Lower Band\n",
    "\n",
    "UB/LB = Midband +/- stdev * K\n",
    "\n",
    "`stdev = train.ewm(span=30).std()`\n",
    "\n",
    "K = the number of standard deviations to go up and down from the EMA\n",
    "\n",
    "### %b, Percent Bandwidth\n",
    "\n",
    "Shows where the last value sits in relation to the bands.\n",
    "\n",
    "%b = last−LB / UB-LB\n",
    "\n",
    "- If %b > 1, data point lies above the upper band\n",
    "- If %b < 0, data point lies below the lower band\n",
    "- If %b == .5, data point lies on the midband."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fa6d363",
   "metadata": {},
   "source": [
    "### Bandwidth\n",
    "\n",
    "The width of the bands\n",
    "\n",
    "Bandwidth = (UB-LB) / midband"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e84ef0f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the window span\n",
    "span = 30\n",
    "\n",
    "# compute midband\n",
    "midband = pages.ewm(span=span).mean()\n",
    "\n",
    "midband.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f205fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute exponential stdev\n",
    "stdev = pages.ewm(span=span).std()\n",
    "\n",
    "stdev.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c6ff743",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute upper and lower bands\n",
    "ub = midband + stdev*3\n",
    "lb = midband - stdev*3\n",
    "ub, lb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c497945c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate ub and lb together into one df, bb\n",
    "bb = pd.concat([ub, lb], axis=1)\n",
    "\n",
    "bb.columns = ['ub', 'lb']\n",
    "bb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78356d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_df = pd.concat([pages, midband, bb], axis=1)\n",
    "my_df.columns = ['pages', 'midband', 'ub', 'lb']\n",
    "my_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d3c18e6",
   "metadata": {},
   "source": [
    "### Plot the bands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc4dfda",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12,8))\n",
    "\n",
    "ax.plot(my_df.index, my_df.pages, label='Number of Pages')\n",
    "\n",
    "ax.plot(my_df.index, my_df.midband, label = '30-day EMA/midband')\n",
    "ax.plot(my_df.index, my_df.ub, label = 'Upper Band')\n",
    "ax.plot(my_df.index, my_df.lb, label = 'Lower Band')\n",
    "\n",
    "ax.legend(loc='best')\n",
    "ax.set_ylabel('Number of pages')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a794e256",
   "metadata": {},
   "source": [
    "### Compute %b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d92c5c73",
   "metadata": {},
   "source": [
    "Each data point will have a %b value that represents its relative position within/around the bollinger bands. It answers the question: Where does this point sit relative to a simple range of expected values? For a trader, its usefulness is based on the validity of an underlying assumption that the overall trend will remain constant. If this is the case, then subsequent points should regress back towards the moving average and can be used in high frequency trading setups (i.e. \"scalping\"). \n",
    "\n",
    "Lets manually compute %b for the last value in the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "440a690c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the last record in our dataset\n",
    "my_df.iloc[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7527437d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the value of the last record\n",
    "last_measure = my_df.iloc[-1].pages\n",
    "last_measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad71cdd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the lower band value on the last date\n",
    "last_lb = my_df.iloc[-1].lb\n",
    "last_lb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b93816",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the upper band value on the last date\n",
    "last_ub = my_df.iloc[-1].ub\n",
    "last_ub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "750814fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute %b\n",
    "last_pct_b = (last_measure - last_lb)/(last_ub - last_lb)\n",
    "\n",
    "print('%b for last datapoint: ', round(last_pct_b, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb28798",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_df.tail(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a45da5f4",
   "metadata": {},
   "source": [
    "We can add a new column that shows the %b for every record in the dataset (except the first because there are no bollinger bands available for that one record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab11d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_df['pct_b'] = (my_df['pages'] - my_df['lb'])/(my_df['ub'] - my_df['lb'])\n",
    "\n",
    "my_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff26310b",
   "metadata": {},
   "source": [
    "Now, where do we see anomalies? We will search for %b values > 1. In this specific example, we don't need to search for values < 0 because a low extreme is not something we are concerned about. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "741e36bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_df[my_df['pct_b']>1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19501d33",
   "metadata": {},
   "source": [
    "No anomalies found. Remember, the cutoff is based on the arbitrary selection for K earlier. We could always pick a different K.\n",
    "\n",
    "Anyways great! There are no anomalies! Problem solved. \n",
    "\n",
    "...not so fast.\n",
    "\n",
    "During our preparation step we resampled the data to a daily period. The bollinger bands and %b are only looking for individual days where the overall aggregate log activity was extreme. If the number of users is large enough, then an individual who is scraping our data may not be extreme enough to push a single day that far from the EMA. \n",
    "\n",
    "We need to dig deeper. Lets look at our data on a user by user basis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "983e9699",
   "metadata": {},
   "outputs": [],
   "source": [
    "def acquire_logs(user=env.user, password=env.password, host=env.host):\n",
    "    '''\n",
    "    This function queries the Codeup MySQL curriculum_logs database and returns a dataframe\n",
    "    '''\n",
    "    url = f'mysql+pymysql://{env.user}:{env.password}@{env.host}/curriculum_logs'\n",
    "    query = '''\n",
    "    SELECT date,\n",
    "           path as endpoint,\n",
    "           user_id,\n",
    "           cohort_id,\n",
    "           ip as source_ip\n",
    "    FROM logs;\n",
    "    '''\n",
    "    df = pd.read_sql(query, url)\n",
    "    return df\n",
    "\n",
    "def one_user_df_prep(df, user):\n",
    "    '''\n",
    "    This function returns a dataframe consisting of data for only a single defined user\n",
    "    '''\n",
    "    df = df[df.user_id == user]\n",
    "    df.date = pd.to_datetime(df.date)\n",
    "    df = df.set_index(df.date)\n",
    "    pages_one_user = df['endpoint'].resample('d').count()\n",
    "    return pages_one_user\n",
    "\n",
    "def compute_pct_b(pages_one_user, span, weight, user):\n",
    "    '''\n",
    "    This function adds the %b of a bollinger band range for the page views of a single user's log activity\n",
    "    '''\n",
    "    # Calculate upper and lower bollinger band\n",
    "    midband = pages_one_user.ewm(span=span).mean()\n",
    "    stdev = pages_one_user.ewm(span=span).std()\n",
    "    ub = midband + stdev*weight\n",
    "    lb = midband - stdev*weight\n",
    "    \n",
    "    # Add upper and lower band values to dataframe\n",
    "    bb = pd.concat([ub, lb], axis=1)\n",
    "    \n",
    "    # Combine all data into a single dataframe\n",
    "    my_df = pd.concat([pages_one_user, midband, bb], axis=1)\n",
    "    my_df.columns = ['pages_one_user', 'midband', 'ub', 'lb']\n",
    "    \n",
    "    # Calculate percent b and relevant user id to dataframe\n",
    "    my_df['pct_b'] = (my_df['pages_one_user'] - my_df['lb'])/(my_df['ub'] - my_df['lb'])\n",
    "    my_df['user_id'] = user\n",
    "    return my_df\n",
    "\n",
    "def plot_bands(my_df, user):\n",
    "    '''\n",
    "    This function plots the bolliger bands of the page views for a single user\n",
    "    '''\n",
    "    fig, ax = plt.subplots(figsize=(12,8))\n",
    "    ax.plot(my_df.index, my_df.pages_one_user, label='Number of Pages, User: '+str(user))\n",
    "    ax.plot(my_df.index, my_df.midband, label = 'EMA/midband')\n",
    "    ax.plot(my_df.index, my_df.ub, label = 'Upper Band')\n",
    "    ax.plot(my_df.index, my_df.lb, label = 'Lower Band')\n",
    "    ax.legend(loc='best')\n",
    "    ax.set_ylabel('Number of Pages')\n",
    "    plt.show()\n",
    "\n",
    "def find_anomalies(df, user, span, weight, plot=False):\n",
    "    '''\n",
    "    This function returns the records where a user's daily activity exceeded the upper limit of a bollinger band range\n",
    "    '''\n",
    "    \n",
    "    # Reduce dataframe to represent a single user\n",
    "    pages_one_user = one_user_df_prep(df, user)\n",
    "    \n",
    "    # Add bollinger band data to dataframe\n",
    "    my_df = compute_pct_b(pages_one_user, span, weight, user)\n",
    "    \n",
    "    # Plot data if requested (plot=True)\n",
    "    if plot:\n",
    "        plot_bands(my_df, user)\n",
    "    \n",
    "    # Return only records that sit outside of bollinger band upper limit\n",
    "    return my_df[my_df.pct_b>1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7761c3bb",
   "metadata": {},
   "source": [
    "# Using our functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d5c9de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = acquire_logs()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fd78af8",
   "metadata": {},
   "source": [
    "#### Test function on a single user:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97cdb327",
   "metadata": {},
   "outputs": [],
   "source": [
    "user = 1\n",
    "span = 30\n",
    "weight = 6\n",
    "user_df = find_anomalies(df, user, span, weight)\n",
    "\n",
    "anomalies = pd.DataFrame()\n",
    "user_df = find_anomalies(df, user, span, weight)\n",
    "anomalies = pd.concat([anomalies, user_df], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d8a6036",
   "metadata": {},
   "outputs": [],
   "source": [
    "anomalies.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d64f6b6",
   "metadata": {},
   "source": [
    "No daily anomalies for user 1\n",
    "\n",
    "#### Use function in a loop examining all users:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edaa3bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "span = 30\n",
    "weight = 3.5\n",
    "\n",
    "anomalies = pd.DataFrame()\n",
    "for u in list(df.user_id.unique()):\n",
    "    user_df = find_anomalies(df, u, span, weight)\n",
    "    anomalies = pd.concat([anomalies, user_df], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "266c260c",
   "metadata": {},
   "outputs": [],
   "source": [
    "anomalies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab9bbdda",
   "metadata": {},
   "source": [
    "What if we sort by %b?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "823db906",
   "metadata": {},
   "outputs": [],
   "source": [
    "anomalies.sort_values(by='pct_b', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45314644",
   "metadata": {},
   "source": [
    "Not super useful. Looks like there could be a fair number of \"false positives\" here. Lets sort by the page counts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d11f94b",
   "metadata": {},
   "outputs": [],
   "source": [
    "anomalies.sort_values(by='pages_one_user', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c16b4bce",
   "metadata": {},
   "source": [
    "#### Wow! User_id #341 looked at 272 pages in a single day. Lets plot their activity:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6490501c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_341 = one_user_df_prep(df, 341)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c518c3e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_341.plot(figsize=(16,8))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "605aa57c",
   "metadata": {},
   "source": [
    "Are there users that show up more frequently than others?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a47083",
   "metadata": {},
   "outputs": [],
   "source": [
    "anomalies.user_id.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb592dc3",
   "metadata": {},
   "source": [
    "Let's plot user #88:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1419a0c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_88 = one_user_df_prep(df, 88)\n",
    "df_88.plot(figsize=(16,8))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bdd2153",
   "metadata": {},
   "source": [
    "# SUSPICIOUSSSSS... {ಠʖಠ}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c21505",
   "metadata": {},
   "source": [
    "# Exercises\n",
    "- file name: `time_series_anomaly_detection.py` or `time_series_anomaly_detection.ipynb`\n",
    "\n",
    "The dataset for these exercises lives in the Codeup Data Science MySQL Server. The database name is curriculum_logs.\n",
    "\n",
    "**Hint**: You will need to explore the database and significantly adjust your acquisition step (yay SQL!)\n",
    "\n",
    "1. Label students by the program they are in.\n",
    "1. Is it possible to identify the user_id of a staff member?\n",
    "1. Identify students who are accessing our curriculum pages beyond the end of their time at Codeup.\n",
    "1. Identify students who present anomalous activity using the Bollinger Band method, but reduce K to 2. \n",
    "1. Plot the access activity of these students.\n",
    "\n",
    "**BONUS:** Identify users who are viewing both the web dev and data science curriculum "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
